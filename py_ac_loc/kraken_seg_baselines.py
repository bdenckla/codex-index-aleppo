# Initially generated by GitHub Copilot.
"""
Run kraken baseline segmentation on Aleppo Codex page columns,
then match detected baselines to a 28-line grid derived from
the manual column-coordinates.

Strategy:
  1. Crop each column using manual bounding box (+ small pad)
  2. Run kraken segmentation on the crop
  3. Compute 28 grid y-positions from the manual coordinates
  4. For each grid slot, find the best-matching kraken baseline
     (nearest by avg_y, within half a line-spacing)
  5. Unmatched grid slots are marked empty (blank or very short)

This naturally handles:
  - Blank lines (no text on the line → no kraken detection → slot empty)
  - Very short lines kraken missed (slot empty)
  - Masorah / marginal lines (not near any grid slot → ignored)

Outputs per-page (into .novc/):
  kraken-seg-{page_id}.json  — detected lines matched to 28-slot grid
  kraken-seg-{page_id}.png   — visualization overlay

Usage (runs in WSL via the kraken venv):
    wsl -- ~/.local/share/kraken-env/bin/python \\
        py_ac_loc/kraken_seg_baselines.py [page_id ...]

    With no args, processes all 24 Job pages (270r-281v).
    With args, processes only the named pages (e.g. 270r 275v).
"""

import json
import sys
import urllib.request
from pathlib import Path

from PIL import Image, ImageDraw
from kraken import blla

WORKSPACE = Path(__file__).resolve().parent.parent
OUT_DIR = WORKSPACE / ".novc"
COORD_DIR = Path(__file__).resolve().parent / "column-coordinates"

ALL_PAGES = [
    f"{leaf}{side}"
    for leaf in range(270, 282)
    for side in ("r", "v")
]

PAD = 5  # pixels of padding around column crop


# ── image helpers ──────────────────────────────────────────────

def _leaf_to_page_n(page_id):
    num = int(page_id[:-1])
    side = page_id[-1]
    return (num - 1) * 2 + 2 + (0 if side == "r" else 1)


def _image_url(page_id):
    n = _leaf_to_page_n(page_id)
    return (
        "https://ia601801.us.archive.org/BookReader/BookReaderImages.php"
        f"?zip=/7/items/aleppo-codex/Aleppo%20Codex_jp2.zip"
        f"&file=Aleppo%20Codex_jp2/Aleppo%20Codex_{n:04d}.jp2"
        f"&id=aleppo-codex&scale=2&rotate=0"
    )


def download_image(page_id):
    cache = OUT_DIR / f"aleppo-page-{page_id}.jpg"
    if cache.exists():
        return Image.open(cache)
    url = _image_url(page_id)
    print(f"  Downloading image...")
    req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
    data = urllib.request.urlopen(req, timeout=60).read()
    cache.write_bytes(data)
    return Image.open(cache)


# ── column geometry ────────────────────────────────────────────

def load_page_data(page_id):
    coord_file = COORD_DIR / f"{page_id}.json"
    return json.loads(coord_file.read_text(encoding="utf-8"))


def grid_y_positions(col_px, lines_per_col):
    """Compute the 28 grid y-positions from manual column coords."""
    y_top = col_px["y"]
    h = col_px["h"]
    spacing = h / (lines_per_col - 1)
    return [y_top + i * spacing for i in range(lines_per_col)]


def crop_column(img, col_px):
    iw, ih = img.size
    x0 = max(0, col_px["x"] - PAD)
    y0 = max(0, col_px["y"] - PAD)
    x1 = min(iw, col_px["x"] + col_px["w"] + PAD)
    y1 = min(ih, col_px["y"] + col_px["h"] + PAD)
    return img.crop((x0, y0, x1, y1)), x0, y0


# ── segmentation + grid matching ──────────────────────────────

def segment_column(img, col_px):
    """Crop column, run kraken, return detected lines in full-image coords."""
    crop, ox, oy = crop_column(img, col_px)
    seg = blla.segment(crop, text_direction="horizontal-rl")
    lines = []
    for li in seg.lines:
        bl = [[p[0] + ox, p[1] + oy] for p in li.baseline]
        bd = [[p[0] + ox, p[1] + oy] for p in li.boundary] if li.boundary else []
        avg_y = sum(p[1] for p in bl) / len(bl)
        avg_x = sum(p[0] for p in bl) / len(bl)
        x_min = min(p[0] for p in bl)
        x_max = max(p[0] for p in bl)
        lines.append({
            "baseline": bl,
            "boundary": bd,
            "avg_y": round(avg_y, 1),
            "avg_x": round(avg_x, 1),
            "x_min": x_min,
            "x_max": x_max,
            "width": x_max - x_min,
        })
    return lines


def match_to_grid(detected_lines, grid_ys, line_spacing):
    """
    Match each detected line to the nearest grid slot.

    For each of the 28 grid positions, find the detected line whose
    avg_y is closest.  Accept if within 60% of a line-spacing.

    We first estimate the systematic y-offset between the grid and
    kraken's baselines by looking at all plausible matches, then
    apply that offset to improve matching.

    Returns:
      - list of 28 slot dicts (one per grid position)
      - the estimated y-offset (px)
      - count of unmatched kraken lines (masorah etc.)
    """
    max_dist = line_spacing * 0.6

    # First pass: estimate systematic offset
    offsets = []
    for gy in grid_ys:
        best = None
        best_dist = float("inf")
        for dl in detected_lines:
            d = abs(dl["avg_y"] - gy)
            if d < best_dist:
                best_dist = d
                best = dl
        if best and best_dist < max_dist:
            offsets.append(best["avg_y"] - gy)

    # Median offset (robust to outliers)
    if offsets:
        offsets.sort()
        offset = offsets[len(offsets) // 2]
    else:
        offset = 0.0

    # Second pass: match with offset-corrected grid
    used = set()
    result = []
    for i, gy in enumerate(grid_ys):
        adjusted_gy = gy + offset
        best_idx = None
        best_dist = float("inf")
        for j, dl in enumerate(detected_lines):
            if j in used:
                continue
            d = abs(dl["avg_y"] - adjusted_gy)
            if d < best_dist:
                best_dist = d
                best_idx = j
        if best_idx is not None and best_dist < max_dist:
            dl = detected_lines[best_idx]
            used.add(best_idx)
            result.append({
                "grid_idx": i,
                "grid_y": round(gy, 1),
                "matched": True,
                "baseline": dl["baseline"],
                "boundary": dl["boundary"],
                "avg_y": dl["avg_y"],
                "avg_x": dl["avg_x"],
                "x_min": dl["x_min"],
                "x_max": dl["x_max"],
                "width": dl["width"],
            })
        else:
            result.append({
                "grid_idx": i,
                "grid_y": round(gy, 1),
                "matched": False,
                "baseline": None,
                "boundary": None,
                "avg_y": None,
                "avg_x": None,
                "x_min": None,
                "x_max": None,
                "width": None,
            })

    n_unmatched_kraken = len(detected_lines) - len(used)
    return result, offset, n_unmatched_kraken


# ── main processing ───────────────────────────────────────────

def segment_page(page_id):
    print(f"\n{'='*50}")
    print(f"Processing {page_id}")
    print(f"{'='*50}")

    img = download_image(page_id)
    w, h = img.size
    page_data = load_page_data(page_id)
    lines_per_col = page_data["lines_per_col"]
    print(f"  Image: {w}x{h}, lines_per_col={lines_per_col}")

    col_results = {}
    for col_key in ("col1", "col2"):
        col_px = page_data["columns"][col_key]["px"]
        spacing = col_px["line_spacing"]
        grid_ys = grid_y_positions(col_px, lines_per_col)

        print(f"  {col_key}: segmenting (col_w={col_px['w']}px, spacing={spacing}px)...")
        detected = segment_column(img, col_px)
        print(f"    kraken found {len(detected)} raw lines")

        matched, offset, n_extra = match_to_grid(detected, grid_ys, spacing)
        n_filled = sum(1 for s in matched if s["matched"])
        n_empty = lines_per_col - n_filled
        print(f"    grid match: {n_filled}/{lines_per_col} filled, "
              f"{n_empty} empty, offset={offset:+.1f}px, "
              f"{n_extra} kraken lines unmatched (masorah etc.)")

        empty_idxs = [s["grid_idx"] for s in matched if not s["matched"]]
        if empty_idxs:
            print(f"    empty grid slots: {empty_idxs}")

        col_results[col_key] = {
            "col_px": col_px,
            "grid_ys": grid_ys,
            "detected_raw": detected,
            "matched": matched,
            "offset": offset,
        }

    # Save JSON
    output = {
        "page": page_id,
        "image_size": {"width": w, "height": h},
        "lines_per_col": lines_per_col,
    }
    for col_key in ("col1", "col2"):
        cr = col_results[col_key]
        output[col_key] = {
            "offset_px": round(cr["offset"], 1),
            "filled": sum(1 for s in cr["matched"] if s["matched"]),
            "empty": sum(1 for s in cr["matched"] if not s["matched"]),
            "slots": [
                {
                    "grid_idx": s["grid_idx"],
                    "grid_y": s["grid_y"],
                    "matched": s["matched"],
                    "baseline": s["baseline"],
                    "boundary": s["boundary"],
                    "avg_y": s["avg_y"],
                    "width": s["width"],
                }
                for s in cr["matched"]
            ],
        }

    json_path = OUT_DIR / f"kraken-seg-{page_id}.json"
    json_path.write_text(json.dumps(output, indent=2))

    # Visualization
    viz = img.copy().convert("RGB")
    draw = ImageDraw.Draw(viz)

    col_colors = {"col1": "red", "col2": "cyan"}
    for col_key in ("col1", "col2"):
        cr = col_results[col_key]
        color = col_colors[col_key]
        px = cr["col_px"]

        # Column bounding box in green
        draw.rectangle(
            [(px["x"], px["y"]), (px["x"] + px["w"], px["y"] + px["h"])],
            outline="lime", width=1,
        )

        # Grid lines in dim yellow
        for i, gy in enumerate(cr["grid_ys"]):
            draw.line(
                [(px["x"], gy), (px["x"] + px["w"], gy)],
                fill=(80, 80, 40), width=1,
            )
            draw.text((px["x"] - 18, gy - 6), str(i), fill=(80, 80, 40))

        # Unmatched kraken lines in dark gray
        for dl in cr["detected_raw"]:
            bl = dl["baseline"]
            if len(bl) >= 2:
                draw.line([tuple(p) for p in bl], fill=(60, 60, 60), width=1)

        # Matched baselines in bright color
        for s in cr["matched"]:
            idx = s["grid_idx"]
            if s["matched"]:
                bl = s["baseline"]
                if len(bl) >= 2:
                    draw.line([tuple(p) for p in bl], fill=color, width=2)
                draw.text((bl[-1][0] + 3, bl[-1][1] - 8),
                          str(idx), fill=color)
            else:
                gy = s["grid_y"]
                cx = px["x"] + px["w"] // 2
                draw.text((cx - 4, gy - 6), "X", fill="yellow")

    viz_path = OUT_DIR / f"kraken-seg-{page_id}.png"
    viz.save(viz_path)
    print(f"  Saved: {json_path.name}, {viz_path.name}")

    return output


# ── entry point ────────────────────────────────────────────────

if __name__ == "__main__":
    pages = sys.argv[1:] if len(sys.argv) > 1 else ALL_PAGES

    results = {}
    for page_id in pages:
        coord_file = COORD_DIR / f"{page_id}.json"
        if not coord_file.exists():
            print(f"Skipping {page_id}: no column-coordinates file")
            continue
        result = segment_page(page_id)
        results[page_id] = result

    # Summary
    print(f"\n{'='*50}")
    print("SUMMARY")
    print(f"{'='*50}")
    for page_id, r in results.items():
        c1f = r["col1"]["filled"]
        c1e = r["col1"]["empty"]
        c2f = r["col2"]["filled"]
        c2e = r["col2"]["empty"]
        print(f"  {page_id}: col1={c1f}/28 ({c1e} empty)  "
              f"col2={c2f}/28 ({c2e} empty)")
